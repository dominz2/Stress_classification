{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98296e81",
   "metadata": {},
   "source": [
    "## Segregating files for fearful and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d149e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import os # interface with underlying OS that python is running on\n",
    "import sys\n",
    "import warnings\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization, Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a6cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DIRECTORY OF AUDIO FILES \n",
    "audio = \"./audio_speech_actors_01-24/\"\n",
    "actor_folders = os.listdir(audio) #list files in audio directory\n",
    "actor_folders.sort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3edee75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FUNCTION TO EXTRACT EMOTION NUMBER\n",
    "emotion = []\n",
    "file_path = []\n",
    "for i in actor_folders:\n",
    "    filename = os.listdir(audio + i) #iterate over Actor folders\n",
    "    for f in filename: # go through files in Actor folder\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        file_path.append(audio + i + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f1f5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     2\n",
       "...  ..\n",
       "1435  8\n",
       "1436  8\n",
       "1437  8\n",
       "1438  8\n",
       "1439  8\n",
       "\n",
       "[1440 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df = pd.DataFrame(emotion)\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f737e4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_01/03-01-01-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_01/03-01-01-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_01/03-01-01-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_01/03-01-01-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_01/03-01-02-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>8</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_24/03-01-08-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>8</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_24/03-01-08-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>8</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_24/03-01-08-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>8</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_24/03-01-08-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>8</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_24/03-01-08-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion                                               path\n",
       "0           1  ./audio_speech_actors_01-24/Actor_01/03-01-01-...\n",
       "1           1  ./audio_speech_actors_01-24/Actor_01/03-01-01-...\n",
       "2           1  ./audio_speech_actors_01-24/Actor_01/03-01-01-...\n",
       "3           1  ./audio_speech_actors_01-24/Actor_01/03-01-01-...\n",
       "4           2  ./audio_speech_actors_01-24/Actor_01/03-01-02-...\n",
       "...       ...                                                ...\n",
       "1435        8  ./audio_speech_actors_01-24/Actor_24/03-01-08-...\n",
       "1436        8  ./audio_speech_actors_01-24/Actor_24/03-01-08-...\n",
       "1437        8  ./audio_speech_actors_01-24/Actor_24/03-01-08-...\n",
       "1438        8  ./audio_speech_actors_01-24/Actor_24/03-01-08-...\n",
       "1439        8  ./audio_speech_actors_01-24/Actor_24/03-01-08-...\n",
       "\n",
       "[1440 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df.columns = ['emotion']\n",
    "audio_df = pd.concat([audio_df,pd.DataFrame(file_path, columns = ['path'])],axis=1)\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5c3fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>5</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_14/03-01-05-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>4</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_10/03-01-04-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>4</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_14/03-01-04-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>4</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_18/03-01-04-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>6</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_04/03-01-06-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>5</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_14/03-01-05-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion                                               path\n",
       "811         5  ./audio_speech_actors_01-24/Actor_14/03-01-05-...\n",
       "560         4  ./audio_speech_actors_01-24/Actor_10/03-01-04-...\n",
       "802         4  ./audio_speech_actors_01-24/Actor_14/03-01-04-...\n",
       "1040        4  ./audio_speech_actors_01-24/Actor_18/03-01-04-...\n",
       "220         6  ./audio_speech_actors_01-24/Actor_04/03-01-06-...\n",
       "812         5  ./audio_speech_actors_01-24/Actor_14/03-01-05-..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df.sample(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90b6dbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_12/03-01-07-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_17/03-01-02-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_01/03-01-02-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>6</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_22/03-01-06-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_18/03-01-07-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_06/03-01-01-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_01/03-01-07-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_06/03-01-04-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_21/03-01-08-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>1</td>\n",
       "      <td>./audio_speech_actors_01-24/Actor_16/03-01-02-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion                                               path\n",
       "709         1  ./audio_speech_actors_01-24/Actor_12/03-01-07-...\n",
       "968         1  ./audio_speech_actors_01-24/Actor_17/03-01-02-...\n",
       "6           1  ./audio_speech_actors_01-24/Actor_01/03-01-02-...\n",
       "1297        6  ./audio_speech_actors_01-24/Actor_22/03-01-06-...\n",
       "1065        1  ./audio_speech_actors_01-24/Actor_18/03-01-07-...\n",
       "302         1  ./audio_speech_actors_01-24/Actor_06/03-01-01-...\n",
       "48          1  ./audio_speech_actors_01-24/Actor_01/03-01-07-...\n",
       "324         1  ./audio_speech_actors_01-24/Actor_06/03-01-04-...\n",
       "1258        1  ./audio_speech_actors_01-24/Actor_21/03-01-08-...\n",
       "907         1  ./audio_speech_actors_01-24/Actor_16/03-01-02-..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are only interested in fearful (stressed) voices, others are considered as natural\n",
    "audio_df['emotion'] = audio_df['emotion'].replace([1, 2, 3, 4, 5, 7, 8], 1)\n",
    "audio_df.sample(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3d64e",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ca816ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6102bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['mfcc'])\n",
    "\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    audio, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=3,sr=44100,offset=0.5)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
    "    mfcc=np.mean(mfcc,axis=0)\n",
    "    df.loc[index] = [mfcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "661b469d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-65.80097, -65.80097, -65.80097, -65.80097, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-63.190464, -62.799866, -63.830635, -60.55258...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-65.81886, -65.81886, -65.81886, -65.81886, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-66.05848, -66.05848, -66.05848, -66.05848, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-70.26777, -70.26777, -70.26777, -70.26777, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>[-58.98881, -58.98881, -60.665466, -60.689583,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>[-54.67716, -54.67716, -54.67716, -54.67716, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>[-56.940815, -56.940815, -56.940815, -56.94081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>[-55.255135, -55.255135, -55.18665, -55.345295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>[-50.366756, -45.98604, -46.046833, -46.525803...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   mfcc\n",
       "0     [-65.80097, -65.80097, -65.80097, -65.80097, -...\n",
       "1     [-63.190464, -62.799866, -63.830635, -60.55258...\n",
       "2     [-65.81886, -65.81886, -65.81886, -65.81886, -...\n",
       "3     [-66.05848, -66.05848, -66.05848, -66.05848, -...\n",
       "4     [-70.26777, -70.26777, -70.26777, -70.26777, -...\n",
       "...                                                 ...\n",
       "1435  [-58.98881, -58.98881, -60.665466, -60.689583,...\n",
       "1436  [-54.67716, -54.67716, -54.67716, -54.67716, -...\n",
       "1437  [-56.940815, -56.940815, -56.940815, -56.94081...\n",
       "1438  [-55.255135, -55.255135, -55.18665, -55.345295...\n",
       "1439  [-50.366756, -45.98604, -46.046833, -46.525803...\n",
       "\n",
       "[1440 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d614ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN ARRAY INTO LIST AND JOIN WITH AUDIO_DF TO GET CORRESPONDING EMOTION LABELS\n",
    "df_combined = pd.concat([audio_df,pd.DataFrame(df['mfcc'].values.tolist())],axis=1)\n",
    "df_combined = df_combined.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12f708e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.drop(columns='path', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6aca0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>-65.800972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-63.190464</td>\n",
       "      <td>-62.799866</td>\n",
       "      <td>-63.830635</td>\n",
       "      <td>-60.552586</td>\n",
       "      <td>-60.821678</td>\n",
       "      <td>-62.073399</td>\n",
       "      <td>-64.889229</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>-65.389946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.805527</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.818863</td>\n",
       "      <td>-65.629539</td>\n",
       "      <td>-64.802628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>-66.058479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>...</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-69.957710</td>\n",
       "      <td>-68.377602</td>\n",
       "      <td>-69.862564</td>\n",
       "      <td>-70.267769</td>\n",
       "      <td>-70.122139</td>\n",
       "      <td>-68.554955</td>\n",
       "      <td>-70.206528</td>\n",
       "      <td>-70.267769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-60.665466</td>\n",
       "      <td>-60.689583</td>\n",
       "      <td>-59.735569</td>\n",
       "      <td>-60.501480</td>\n",
       "      <td>-60.420517</td>\n",
       "      <td>-59.816250</td>\n",
       "      <td>-60.189262</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.973309</td>\n",
       "      <td>-58.984501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.624363</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.156242</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.115520</td>\n",
       "      <td>-54.271080</td>\n",
       "      <td>-54.677158</td>\n",
       "      <td>-54.636047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.943363</td>\n",
       "      <td>-57.077030</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.438938</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.940815</td>\n",
       "      <td>-56.923138</td>\n",
       "      <td>-56.938293</td>\n",
       "      <td>-56.927471</td>\n",
       "      <td>-56.865555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1</td>\n",
       "      <td>-55.255135</td>\n",
       "      <td>-55.255135</td>\n",
       "      <td>-55.186649</td>\n",
       "      <td>-55.345295</td>\n",
       "      <td>-55.053379</td>\n",
       "      <td>-53.088177</td>\n",
       "      <td>-52.199924</td>\n",
       "      <td>-52.218304</td>\n",
       "      <td>-52.633869</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.756596</td>\n",
       "      <td>-50.436131</td>\n",
       "      <td>-49.073444</td>\n",
       "      <td>-49.137142</td>\n",
       "      <td>-51.701096</td>\n",
       "      <td>-54.797939</td>\n",
       "      <td>-55.255135</td>\n",
       "      <td>-54.609993</td>\n",
       "      <td>-52.202969</td>\n",
       "      <td>-51.720993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1</td>\n",
       "      <td>-50.366756</td>\n",
       "      <td>-45.986038</td>\n",
       "      <td>-46.046833</td>\n",
       "      <td>-46.525803</td>\n",
       "      <td>-47.946480</td>\n",
       "      <td>-44.790188</td>\n",
       "      <td>-43.489738</td>\n",
       "      <td>-46.490620</td>\n",
       "      <td>-50.799656</td>\n",
       "      <td>...</td>\n",
       "      <td>-53.574356</td>\n",
       "      <td>-52.219002</td>\n",
       "      <td>-50.779594</td>\n",
       "      <td>-47.774746</td>\n",
       "      <td>-47.851891</td>\n",
       "      <td>-48.792416</td>\n",
       "      <td>-50.168167</td>\n",
       "      <td>-52.202194</td>\n",
       "      <td>-53.823738</td>\n",
       "      <td>-53.829815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion          0          1          2          3          4  \\\n",
       "0           1 -65.800972 -65.800972 -65.800972 -65.800972 -65.800972   \n",
       "1           1 -63.190464 -62.799866 -63.830635 -60.552586 -60.821678   \n",
       "2           1 -65.818863 -65.818863 -65.818863 -65.818863 -65.805527   \n",
       "3           1 -66.058479 -66.058479 -66.058479 -66.058479 -66.058479   \n",
       "4           1 -70.267769 -70.267769 -70.267769 -70.267769 -70.267769   \n",
       "...       ...        ...        ...        ...        ...        ...   \n",
       "1435        1 -58.988811 -58.988811 -60.665466 -60.689583 -59.735569   \n",
       "1436        1 -54.677158 -54.677158 -54.677158 -54.677158 -54.677158   \n",
       "1437        1 -56.940815 -56.940815 -56.940815 -56.940815 -56.940815   \n",
       "1438        1 -55.255135 -55.255135 -55.186649 -55.345295 -55.053379   \n",
       "1439        1 -50.366756 -45.986038 -46.046833 -46.525803 -47.946480   \n",
       "\n",
       "              5          6          7          8  ...        249        250  \\\n",
       "0    -65.800972 -65.800972 -65.800972 -65.800972  ...   0.000000   0.000000   \n",
       "1    -62.073399 -64.889229 -65.389946 -65.389946  ...   0.000000   0.000000   \n",
       "2    -65.818863 -65.818863 -65.629539 -64.802628  ...   0.000000   0.000000   \n",
       "3    -66.058479 -66.058479 -66.058479 -66.058479  ...   0.000000   0.000000   \n",
       "4    -70.267769 -70.267769 -70.267769 -70.267769  ... -70.267769 -70.267769   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1435 -60.501480 -60.420517 -59.816250 -60.189262  ... -58.973309 -58.984501   \n",
       "1436 -54.677158 -54.677158 -54.677158 -54.677158  ... -54.624363 -54.677158   \n",
       "1437 -56.943363 -57.077030 -56.940815 -56.940815  ... -56.438938 -56.940815   \n",
       "1438 -53.088177 -52.199924 -52.218304 -52.633869  ... -49.756596 -50.436131   \n",
       "1439 -44.790188 -43.489738 -46.490620 -50.799656  ... -53.574356 -52.219002   \n",
       "\n",
       "            251        252        253        254        255        256  \\\n",
       "0      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4    -69.957710 -68.377602 -69.862564 -70.267769 -70.122139 -68.554955   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1435   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1436 -54.677158 -54.156242 -54.677158 -54.677158 -54.115520 -54.271080   \n",
       "1437 -56.940815 -56.940815 -56.940815 -56.940815 -56.923138 -56.938293   \n",
       "1438 -49.073444 -49.137142 -51.701096 -54.797939 -55.255135 -54.609993   \n",
       "1439 -50.779594 -47.774746 -47.851891 -48.792416 -50.168167 -52.202194   \n",
       "\n",
       "            257        258  \n",
       "0      0.000000   0.000000  \n",
       "1      0.000000   0.000000  \n",
       "2      0.000000   0.000000  \n",
       "3      0.000000   0.000000  \n",
       "4    -70.206528 -70.267769  \n",
       "...         ...        ...  \n",
       "1435   0.000000   0.000000  \n",
       "1436 -54.677158 -54.636047  \n",
       "1437 -56.927471 -56.865555  \n",
       "1438 -52.202969 -51.720993  \n",
       "1439 -53.823738 -53.829815  \n",
       "\n",
       "[1440 rows x 260 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df3f06",
   "metadata": {},
   "source": [
    "## preparing data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5fd065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT DATA\n",
    "train,test = train_test_split(df_combined, test_size=0.2, random_state=0,\n",
    "                               stratify=df_combined[['emotion']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3516bd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1</td>\n",
       "      <td>-65.875824</td>\n",
       "      <td>-65.875824</td>\n",
       "      <td>-65.875824</td>\n",
       "      <td>-65.875824</td>\n",
       "      <td>-65.875824</td>\n",
       "      <td>-65.875824</td>\n",
       "      <td>-65.875824</td>\n",
       "      <td>-65.875824</td>\n",
       "      <td>-65.875824</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.538139</td>\n",
       "      <td>-47.644451</td>\n",
       "      <td>-44.814541</td>\n",
       "      <td>-44.929886</td>\n",
       "      <td>-48.816364</td>\n",
       "      <td>-54.223652</td>\n",
       "      <td>-52.589237</td>\n",
       "      <td>-47.685589</td>\n",
       "      <td>-47.041172</td>\n",
       "      <td>-52.205200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>1</td>\n",
       "      <td>-58.739071</td>\n",
       "      <td>-58.816528</td>\n",
       "      <td>-58.264206</td>\n",
       "      <td>-57.426785</td>\n",
       "      <td>-56.464973</td>\n",
       "      <td>-52.486942</td>\n",
       "      <td>-47.010036</td>\n",
       "      <td>-45.936707</td>\n",
       "      <td>-48.372471</td>\n",
       "      <td>...</td>\n",
       "      <td>-59.849724</td>\n",
       "      <td>-59.577488</td>\n",
       "      <td>-59.678612</td>\n",
       "      <td>-60.250324</td>\n",
       "      <td>-60.250324</td>\n",
       "      <td>-60.250324</td>\n",
       "      <td>-60.250324</td>\n",
       "      <td>-60.250324</td>\n",
       "      <td>-60.250324</td>\n",
       "      <td>-60.250324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.540245</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.598713</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "      <td>-39.749325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.261780</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.027588</td>\n",
       "      <td>-65.404327</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "      <td>-65.427315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>-50.407593</td>\n",
       "      <td>-50.407593</td>\n",
       "      <td>-50.407593</td>\n",
       "      <td>-49.911777</td>\n",
       "      <td>-48.696651</td>\n",
       "      <td>-47.160969</td>\n",
       "      <td>-46.595181</td>\n",
       "      <td>-48.091354</td>\n",
       "      <td>-48.508846</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.531654</td>\n",
       "      <td>-49.237728</td>\n",
       "      <td>-49.907722</td>\n",
       "      <td>-39.250950</td>\n",
       "      <td>-33.475601</td>\n",
       "      <td>-35.550926</td>\n",
       "      <td>-39.312279</td>\n",
       "      <td>-38.523651</td>\n",
       "      <td>-38.051067</td>\n",
       "      <td>-38.246758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>1</td>\n",
       "      <td>-46.288433</td>\n",
       "      <td>-48.978920</td>\n",
       "      <td>-53.023132</td>\n",
       "      <td>-54.253548</td>\n",
       "      <td>-55.656780</td>\n",
       "      <td>-56.751869</td>\n",
       "      <td>-56.982365</td>\n",
       "      <td>-57.003750</td>\n",
       "      <td>-56.196892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1</td>\n",
       "      <td>-55.958439</td>\n",
       "      <td>-55.958439</td>\n",
       "      <td>-55.958439</td>\n",
       "      <td>-55.958439</td>\n",
       "      <td>-55.958439</td>\n",
       "      <td>-55.958439</td>\n",
       "      <td>-55.958439</td>\n",
       "      <td>-55.958439</td>\n",
       "      <td>-55.958439</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.506466</td>\n",
       "      <td>-55.583027</td>\n",
       "      <td>-55.845669</td>\n",
       "      <td>-55.850628</td>\n",
       "      <td>-54.927525</td>\n",
       "      <td>-55.205528</td>\n",
       "      <td>-55.846523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1</td>\n",
       "      <td>-56.790115</td>\n",
       "      <td>-55.447914</td>\n",
       "      <td>-53.428570</td>\n",
       "      <td>-54.689133</td>\n",
       "      <td>-54.845772</td>\n",
       "      <td>-51.445438</td>\n",
       "      <td>-50.770596</td>\n",
       "      <td>-50.176628</td>\n",
       "      <td>-50.047592</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.273964</td>\n",
       "      <td>-53.099472</td>\n",
       "      <td>-53.354042</td>\n",
       "      <td>-53.474606</td>\n",
       "      <td>-54.493511</td>\n",
       "      <td>-55.937416</td>\n",
       "      <td>-58.199486</td>\n",
       "      <td>-58.295376</td>\n",
       "      <td>-57.271141</td>\n",
       "      <td>-58.632534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-56.735863</td>\n",
       "      <td>-56.598503</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>-57.254601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>1</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>-68.325424</td>\n",
       "      <td>...</td>\n",
       "      <td>-60.588387</td>\n",
       "      <td>-61.961018</td>\n",
       "      <td>-61.186680</td>\n",
       "      <td>-61.114937</td>\n",
       "      <td>-60.467003</td>\n",
       "      <td>-63.210453</td>\n",
       "      <td>-66.898552</td>\n",
       "      <td>-65.732323</td>\n",
       "      <td>-67.273415</td>\n",
       "      <td>-67.667511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1152 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion          0          1          2          3          4  \\\n",
       "186         1 -65.875824 -65.875824 -65.875824 -65.875824 -65.875824   \n",
       "1285        1 -58.739071 -58.816528 -58.264206 -57.426785 -56.464973   \n",
       "275         1 -39.749325 -39.749325 -39.749325 -39.749325 -39.749325   \n",
       "14          1 -65.427315 -65.427315 -65.261780 -65.427315 -65.427315   \n",
       "199         1 -50.407593 -50.407593 -50.407593 -49.911777 -48.696651   \n",
       "...       ...        ...        ...        ...        ...        ...   \n",
       "1083        1 -46.288433 -48.978920 -53.023132 -54.253548 -55.656780   \n",
       "210         1 -55.958439 -55.958439 -55.958439 -55.958439 -55.958439   \n",
       "1136        1 -56.790115 -55.447914 -53.428570 -54.689133 -54.845772   \n",
       "419         1 -57.254601 -57.254601 -57.254601 -57.254601 -56.735863   \n",
       "904         1 -68.325424 -68.325424 -68.325424 -68.325424 -68.325424   \n",
       "\n",
       "              5          6          7          8  ...        249        250  \\\n",
       "186  -65.875824 -65.875824 -65.875824 -65.875824  ... -46.538139 -47.644451   \n",
       "1285 -52.486942 -47.010036 -45.936707 -48.372471  ... -59.849724 -59.577488   \n",
       "275  -39.749325 -39.749325 -39.749325 -39.749325  ... -39.749325 -39.749325   \n",
       "14   -65.427315 -65.027588 -65.404327 -65.427315  ... -65.427315 -65.427315   \n",
       "199  -47.160969 -46.595181 -48.091354 -48.508846  ... -49.531654 -49.237728   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1083 -56.751869 -56.982365 -57.003750 -56.196892  ...   0.000000   0.000000   \n",
       "210  -55.958439 -55.958439 -55.958439 -55.958439  ... -55.506466 -55.583027   \n",
       "1136 -51.445438 -50.770596 -50.176628 -50.047592  ... -50.273964 -53.099472   \n",
       "419  -56.598503 -57.254601 -57.254601 -57.254601  ... -57.254601 -57.254601   \n",
       "904  -68.325424 -68.325424 -68.325424 -68.325424  ... -60.588387 -61.961018   \n",
       "\n",
       "            251        252        253        254        255        256  \\\n",
       "186  -44.814541 -44.929886 -48.816364 -54.223652 -52.589237 -47.685589   \n",
       "1285 -59.678612 -60.250324 -60.250324 -60.250324 -60.250324 -60.250324   \n",
       "275  -39.540245 -39.749325 -39.749325 -39.749325 -39.598713 -39.749325   \n",
       "14   -65.427315 -65.427315 -65.427315 -65.427315 -65.427315 -65.427315   \n",
       "199  -49.907722 -39.250950 -33.475601 -35.550926 -39.312279 -38.523651   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1083   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "210  -55.845669 -55.850628 -54.927525 -55.205528 -55.846523   0.000000   \n",
       "1136 -53.354042 -53.474606 -54.493511 -55.937416 -58.199486 -58.295376   \n",
       "419  -57.254601 -57.254601 -57.254601 -57.254601 -57.254601   0.000000   \n",
       "904  -61.186680 -61.114937 -60.467003 -63.210453 -66.898552 -65.732323   \n",
       "\n",
       "            257        258  \n",
       "186  -47.041172 -52.205200  \n",
       "1285 -60.250324 -60.250324  \n",
       "275  -39.749325 -39.749325  \n",
       "14   -65.427315 -65.427315  \n",
       "199  -38.051067 -38.246758  \n",
       "...         ...        ...  \n",
       "1083   0.000000   0.000000  \n",
       "210    0.000000   0.000000  \n",
       "1136 -57.271141 -58.632534  \n",
       "419    0.000000   0.000000  \n",
       "904  -67.273415 -67.667511  \n",
       "\n",
       "[1152 rows x 260 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97e99754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152, 259)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.iloc[:, 1:]\n",
    "y_train = train.iloc[:,0]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5d58171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 259)\n"
     ]
    }
   ],
   "source": [
    "X_test = test.iloc[:,1:]\n",
    "y_test = test.iloc[:,0]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d28b7",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a959a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1f64cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN DATA INTO ARRAYS FOR KERAS\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f0e98b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c2b9e16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# # ONE HOT ENCODE THE TARGET\n",
    "# # CNN REQUIRES INPUT AND OUTPUT ARE NUMBERS\n",
    "# lb = LabelEncoder()\n",
    "# y_train = to_categorical(lb.fit_transform(y_train))\n",
    "# y_test = to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "# print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00cd1d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "DummyClassifier(strategy='stratified')\n",
    "dummy_clf.predict(X_test)\n",
    "dummy_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a9e93dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7951388888888888"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f8f795a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 250, 64)           704       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 241, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 21, 128)           163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 312,769\n",
      "Trainable params: 312,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "#BUILD 1D CNN LAYERS\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Conv1D(64, kernel_size=(10), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "model.add(layers.Conv1D(128, kernel_size=(10),activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model.add(layers.MaxPooling1D(pool_size=(8)))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Conv1D(128, kernel_size=(10),activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=(8)))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='BinaryCrossentropy', optimizer=opt,metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d414855e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#X_test.shape\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "#X_test.shape\n",
    "X_train.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "956a6e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 259, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESHAPE DATA TO INCLUDE 3D TENSOR \n",
    "X_train = X_train[:,:,np.newaxis]\n",
    "X_test = X_test[:,:,np.newaxis]\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e9dec4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 259, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b179a3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42ead6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/40\n",
      "36/36 [==============================] - 2s 43ms/step - loss: -1198.6792 - binary_accuracy: 0.8464 - val_loss: -7810.9106 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 2/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -100455.5938 - binary_accuracy: 0.8663 - val_loss: -397364.1875 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 3/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -1927929.1250 - binary_accuracy: 0.8663 - val_loss: -5732385.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 4/40\n",
      "36/36 [==============================] - 1s 35ms/step - loss: -17264764.0000 - binary_accuracy: 0.8663 - val_loss: -38274764.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 5/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -79755064.0000 - binary_accuracy: 0.8663 - val_loss: -154346464.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 6/40\n",
      "36/36 [==============================] - 1s 35ms/step - loss: -270942240.0000 - binary_accuracy: 0.8663 - val_loss: -470798528.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 7/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -747764224.0000 - binary_accuracy: 0.8663 - val_loss: -1222661504.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 8/40\n",
      "36/36 [==============================] - 1s 35ms/step - loss: -1802409984.0000 - binary_accuracy: 0.8663 - val_loss: -2713832960.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 9/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -3792695040.0000 - binary_accuracy: 0.8663 - val_loss: -5436666368.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 10/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -7314653696.0000 - binary_accuracy: 0.8663 - val_loss: -10013886464.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 11/40\n",
      "36/36 [==============================] - 1s 37ms/step - loss: -12589894656.0000 - binary_accuracy: 0.8663 - val_loss: -17392355328.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 12/40\n",
      "36/36 [==============================] - 1s 37ms/step - loss: -21081088000.0000 - binary_accuracy: 0.8663 - val_loss: -27885547520.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 13/40\n",
      "36/36 [==============================] - 1s 39ms/step - loss: -33546647552.0000 - binary_accuracy: 0.8663 - val_loss: -43726798848.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 14/40\n",
      "36/36 [==============================] - 1s 35ms/step - loss: -51231899648.0000 - binary_accuracy: 0.8663 - val_loss: -66507423744.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 15/40\n",
      "36/36 [==============================] - 1s 35ms/step - loss: -75079196672.0000 - binary_accuracy: 0.8663 - val_loss: -96892076032.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 16/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -108843425792.0000 - binary_accuracy: 0.8663 - val_loss: -135458947072.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 17/40\n",
      "36/36 [==============================] - 1s 41ms/step - loss: -154377027584.0000 - binary_accuracy: 0.8663 - val_loss: -189438705664.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 18/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -211492077568.0000 - binary_accuracy: 0.8663 - val_loss: -256727171072.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 19/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -283479506944.0000 - binary_accuracy: 0.8663 - val_loss: -342843392000.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 20/40\n",
      "36/36 [==============================] - 1s 35ms/step - loss: -367707684864.0000 - binary_accuracy: 0.8663 - val_loss: -443627339776.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 21/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -486421266432.0000 - binary_accuracy: 0.8663 - val_loss: -576643989504.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 22/40\n",
      "36/36 [==============================] - 1s 35ms/step - loss: -614266372096.0000 - binary_accuracy: 0.8663 - val_loss: -726500048896.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 23/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -765198139392.0000 - binary_accuracy: 0.8663 - val_loss: -910834073600.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 24/40\n",
      "36/36 [==============================] - 1s 35ms/step - loss: -961027964928.0000 - binary_accuracy: 0.8663 - val_loss: -1128782102528.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 25/40\n",
      "36/36 [==============================] - 1s 38ms/step - loss: -1178718830592.0000 - binary_accuracy: 0.8663 - val_loss: -1380367990784.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 26/40\n",
      "36/36 [==============================] - 1s 38ms/step - loss: -1455656796160.0000 - binary_accuracy: 0.8663 - val_loss: -1672754364416.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 27/40\n",
      "36/36 [==============================] - 1s 37ms/step - loss: -1721822609408.0000 - binary_accuracy: 0.8663 - val_loss: -2013213229056.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 28/40\n",
      "36/36 [==============================] - 1s 37ms/step - loss: -2115448733696.0000 - binary_accuracy: 0.8663 - val_loss: -2400490094592.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 29/40\n",
      "36/36 [==============================] - 1s 37ms/step - loss: -2515991527424.0000 - binary_accuracy: 0.8663 - val_loss: -2860985876480.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 30/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -2967013949440.0000 - binary_accuracy: 0.8663 - val_loss: -3378160599040.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 31/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -3471056568320.0000 - binary_accuracy: 0.8663 - val_loss: -3946580017152.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40\n",
      "36/36 [==============================] - 1s 35ms/step - loss: -4010230415360.0000 - binary_accuracy: 0.8663 - val_loss: -4594074124288.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 33/40\n",
      "36/36 [==============================] - 1s 37ms/step - loss: -4727811080192.0000 - binary_accuracy: 0.8663 - val_loss: -5313691385856.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 34/40\n",
      "36/36 [==============================] - 1s 38ms/step - loss: -5530351828992.0000 - binary_accuracy: 0.8663 - val_loss: -6144672661504.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 35/40\n",
      "36/36 [==============================] - 1s 35ms/step - loss: -6298319454208.0000 - binary_accuracy: 0.8663 - val_loss: -7024908173312.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 36/40\n",
      "36/36 [==============================] - 1s 39ms/step - loss: -7340713050112.0000 - binary_accuracy: 0.8663 - val_loss: -8082270715904.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 37/40\n",
      "36/36 [==============================] - 1s 37ms/step - loss: -8319087935488.0000 - binary_accuracy: 0.8663 - val_loss: -9156609179648.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 38/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -9287973732352.0000 - binary_accuracy: 0.8663 - val_loss: -10399890014208.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 39/40\n",
      "36/36 [==============================] - 1s 36ms/step - loss: -10614719119360.0000 - binary_accuracy: 0.8663 - val_loss: -11735530471424.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 40/40\n",
      "36/36 [==============================] - 1s 41ms/step - loss: -11887313944576.0000 - binary_accuracy: 0.8663 - val_loss: -13198213251072.0000 - val_binary_accuracy: 0.8681\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "# FIT MODEL AND USE CHECKPOINT TO SAVE BEST MODEL\n",
    "checkpoint = ModelCheckpoint(\"best_initial_model.hdf5\", monitor='val_accuracy', verbose=1,\n",
    "    save_best_only=True, mode='max', period=1, save_weights_only=True)\n",
    "\n",
    "model_history=model.fit(X_train, y_train,batch_size=32, epochs=40, validation_data=(X_test, y_test),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c16fc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAW6ElEQVR4nO3dfZRkdX3n8feHmcFBBDEzE6IMyqggohEiLT4coyhRAWM4OT6BKGpcOfgUTdYsxJONu2v27JoNiaugk5ElamIgRlHRg6BilDWIMhgeBB8yjsi0wDKAj+AAA9/94952ip7u29XN3O6anvfrnDpT995f3frW70zXp+791f1VqgpJkqaz20IXIEkabQaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0GhXUKSA5JUkqVDtH1Nkq/OR13SzsCg0MhJcn2Su5OsnLT+yvbN/oAFKm2wlj2T/CLJBQtdi9Q3g0Kj6gfACRMLSX4T2GPhytnOS4C7gOcnefh8PvEwR0XSjmRQaFT9PXDSwPKrgY8MNkjy0CQfSbI5yQ+T/FmS3dptS5L8VZJbk2wEXjjFY/9PkpuS/CjJXyRZMov6Xg2sBa4GTpy072cmuTTJT5JsSvKadv0eSU5va/1pkq+2645MMj5pH9cn+Z32/n9J8vEk/5DkZ8BrkhyR5Gvtc9yU5Iwkuw88/glJvpDk9iT/L8k7kvxGkjuTrBhod3jbf8tm8dq1izEoNKouA/ZO8vj2DfzlwD9MavM+4KHAo4Fn0wTLa9ttrwd+F/gtYIzmCGDQh4GtwGPbNs8H/sMwhSV5JHAk8NH2dtKkbZ9ra1sFHAZc2W7+K+Bw4BnArwH/CbhvmOcEjgM+DuzTPue9wB8BK4GnA0cBb2xr2Av4InAh8Ij2NV5cVTcDXwZeNrDfVwLnVtU9Q9ahXZBBoVE2cVTxPOA7wI8mNgyEx59W1c+r6nrgdOBVbZOXAe+pqk1VdTvwPwYeuy9wDPC2qrqjqm4B/gY4fsi6TgKurqrrgHOAJyT5rXbbicAXq+qcqrqnqm6rqivbI50/AN5aVT+qqnur6tKqumvI5/xaVX2qqu6rql9W1RVVdVlVbW1f+9/ShCU0AXlzVZ1eVVva/vl6u+3DNOEw0Ycn0PSzNC3PdWqU/T1wCbCGSaedaD5J7w78cGDdD4H92vuPADZN2jbhUcAy4KYkE+t2m9S+y0nABwGq6sYkX6E5FfVvwP7A96d4zEpg+TTbhnG/2pIcBPw1zdHSg2n+lq9oN09XA8CngbVJHg0cBPy0qr4xx5q0i/CIQiOrqn5IM6h9LHDepM23AvfQvOlPeCTbjjpuonnDHNw2YRPNQPTKqtqnve1dVU+YqaYkzwAOBP40yc1JbgaeCpzQDjJvAh4zxUNvBbZMs+0Omjf7iedYQnPaatDkaZ4/QHOUdWBV7Q28A5hIvelqoKq2AB+jOfJ5FR5NaAgGhUbd64DnVtUdgyur6l6aN7z/nmSvJI8C/pht4xgfA/4wyeokDwNOG3jsTcDngdOT7J1ktySPSfJsZvZq4AvAITTjD4cBT6R5oz+GZvzgd5K8LMnSJCuSHFZV9wFnA3+d5BHtYPvTkzwI+B6wPMkL20HlPwMeNEMdewE/A36R5GDgDQPbPgv8RpK3JXlQ2z9PHdj+EeA1wO+x/biPtB2DQiOtqr5fVeun2fwWmk/jG4GvAv9I82YMzamhi4CrgG+y/RHJSTSnrq4DfkwzUNz5Ndcky2nGPt5XVTcP3H5A88n81VV1A80R0H8EbqcZyD603cXbgWuAy9tt7wZ2q6qf0gxEn0VzRHQHcL9vQU3h7cArgJ+3r/WfJjZU1c9pxnVeBNwM/DvwnIHt/0oziP7NdnxD6hR/uEja9ST5EvCPVXXWQtei0WdQSLuYJE+hOX22f3v0IXXq7dRTkrOT3JLkW9NsT5L3JtmQ5OokT+6rFkmNJB+mucbibYaEhtXbEUWSZwG/AD5SVU+cYvuxNOeYj6X51sj/rqqnTm4nSVpYvR1RVNUlNAN20zmOJkSqqi4D9pnvOXMkSTNbyAvu9uP+FxGNt+tumtwwycnAyQB77rnn4QcffPC8FChJi8UVV1xxa1VNvj5nKAsZFJli3ZTnwapqHbAOYGxsrNavn+7bkpKkqST54cytpraQ11GMc/8rZ1cDNy5QLZKkaSxkUJwPnNR+++lpNHPObHfaSZK0sHo79ZTkHJqpmFe2c+2/k2YiNqpqLXABzTeeNgB3sm16aEnSCOktKKrqhBm2F/CmHfFc99xzD+Pj42zZsmW7bcuXL2f16tUsW+bvskjSXCyKacbHx8fZa6+9OOCAAxiYNpqq4rbbbmN8fJw1a9YsYIWStPNaFJMCbtmyhRUrVtwvJACSsGLFiimPNCRJw1kUQQFsFxIzrZckDWfRBIUkqR8GhSSp06IJiukmN3QadUl6YBZFUCxfvpzbbrttu1CY+NbT8uXLF6gySdr5LYqvx65evZrx8XE2b9683baJ6ygkSXOzKIJi2bJlXichST1ZFKeeJEn9MSgkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ16DYokRyf5bpINSU6bYvtDk3wmyVVJrk3y2j7rkSTNXm9BkWQJcCZwDHAIcEKSQyY1exNwXVUdChwJnJ5k975qkiTNXp9HFEcAG6pqY1XdDZwLHDepTQF7JQnwEOB2YGuPNUmSZqnPoNgP2DSwPN6uG3QG8HjgRuAa4K1Vdd/kHSU5Ocn6JOs3b97cV72SpCn0GRSZYl1NWn4BcCXwCOAw4Iwke2/3oKp1VTVWVWOrVq3a0XVKkjr0GRTjwP4Dy6tpjhwGvRY4rxobgB8AB/dYkyRplvoMisuBA5OsaQeojwfOn9TmBuAogCT7Ao8DNvZYkyRplpb2teOq2prkzcBFwBLg7Kq6Nskp7fa1wLuADyW5huZU1alVdWtfNUmSZq+3oACoqguACyatWztw/0bg+X3WIEl6YLwyW5LUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdeo1KJIcneS7STYkOW2aNkcmuTLJtUm+0mc9kqTZW9rXjpMsAc4EngeMA5cnOb+qrhtosw/wfuDoqrohya/3VY8kaW76PKI4AthQVRur6m7gXOC4SW1eAZxXVTcAVNUtPdYjSZqDPoNiP2DTwPJ4u27QQcDDknw5yRVJTppqR0lOTrI+yfrNmzf3VK4kaSp9BkWmWFeTlpcChwMvBF4A/OckB233oKp1VTVWVWOrVq3a8ZVKkqY1Y1Ak+d0kcwmUcWD/geXVwI1TtLmwqu6oqluBS4BD5/BckqSeDBMAxwP/nuQvkzx+Fvu+HDgwyZoku7f7OX9Sm08Dv51kaZIHA08Fvj2L55Ak9WzGbz1V1SuT7A2cAPxdkgL+Djinqn7e8bitSd4MXAQsAc6uqmuTnNJuX1tV305yIXA1cB9wVlV964G/LEnSjpKqycMG0zRMVgKvBN5G86n/scB7q+p9vVU3hbGxsVq/fv18PqUk7fSSXFFVY3N57DBjFC9K8kngS8Ay4IiqOoZmLOHtc3lSSdLOY5gL7l4K/E1VXTK4sqruTPIH/ZQlSRoVwwTFO4GbJhaS7AHsW1XXV9XFvVUmSRoJw3zr6Z9pBpon3NuukyTtAoYJiqXtFBwAtPd3768kSdIoGSYoNif5vYmFJMcBt/ZXkiRplAwzRnEK8NEkZ9BMy7EJmHJOJknS4jPMBXffB56W5CE0111Me5GdJGnxGer3KJK8EHgCsDxp5vqrqv/WY12SpBExzAV3a4GXA2+hOfX0UuBRPdclSRoRwwxmP6OqTgJ+XFX/FXg6958VVpK0iA0TFFvaf+9M8gjgHmBNfyVJkkbJMGMUn2l/2/p/Ad+k+fGhD/ZZlCRpdHQGRfuDRRdX1U+ATyT5LLC8qn46H8VJkhZe56mnqroPOH1g+S5DQpJ2LcOMUXw+yYsz8b1YSdIuZZgxij8G9gS2JtlC8xXZqqq9e61MkjQShrkye6/5KESSNJpmDIokz5pq/eQfMpIkLU7DnHr6k4H7y4EjgCuA5/ZSkSRppAxz6ulFg8tJ9gf+sreKJEkjZZhvPU02DjxxRxciSRpNw4xRvI/mamxoguUw4Koea5IkjZBhxijWD9zfCpxTVf/aUz2SpBEzTFB8HNhSVfcCJFmS5MFVdWe/pUmSRsEwYxQXA3sMLO8BfLGfciRJo2aYoFheVb+YWGjvP7i/kiRJo2SYoLgjyZMnFpIcDvyyv5IkSaNkmDGKtwH/nOTGdvnhND+NKknaBQxzwd3lSQ4GHkczIeB3quqe3iuTJI2EGU89JXkTsGdVfauqrgEekuSN/ZcmSRoFw4xRvL79hTsAqurHwOt7q0iSNFKGCYrdBn+0KMkSYPf+SpIkjZJhBrMvAj6WZC3NVB6nAJ/rtSpJ0sgYJihOBU4G3kAzmP1vNN98kiTtAmY89VRV9wGXARuBMeAo4NvD7DzJ0Um+m2RDktM62j0lyb1JXjJk3ZKkeTLtEUWSg4DjgROA24B/Aqiq5wyz43Ys40zgeTRTk1+e5Pyqum6Kdu+mOcUlSRoxXUcU36E5enhRVT2zqt4H3DuLfR8BbKiqjVV1N3AucNwU7d4CfAK4ZRb7liTNk66geDFwM/AvST6Y5CiaMYph7QdsGlgeb9f9SpL9gN8H1nbtKMnJSdYnWb958+ZZlCBJeqCmDYqq+mRVvRw4GPgy8EfAvkk+kOT5Q+x7qlCpScvvAU6dmMK8o5Z1VTVWVWOrVq0a4qklSTvKMFN43AF8FPhokl8DXgqcBnx+hoeOA/sPLK8GbpzUZgw4t71MYyVwbJKtVfWpoaqXJPVumK/H/kpV3Q78bXubyeXAgUnWAD+iGRh/xaT9rZm4n+RDwGcNCUkaLbMKitmoqq1J3kzzbaYlwNlVdW2SU9rtneMSkqTR0FtQAFTVBcAFk9ZNGRBV9Zo+a5Ekzc0wcz1JknZhBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpk0EhSepkUEiSOhkUkqROBoUkqZNBIUnqZFBIkjoZFJKkTgaFJKmTQSFJ6mRQSJI6GRSSpE4GhSSpU69BkeToJN9NsiHJaVNsPzHJ1e3t0iSH9lmPJGn2eguKJEuAM4FjgEOAE5IcMqnZD4BnV9WTgHcB6/qqR5I0N30eURwBbKiqjVV1N3AucNxgg6q6tKp+3C5eBqzusR5J0hz0GRT7AZsGlsfbddN5HfC5qTYkOTnJ+iTrN2/evANLlCTNpM+gyBTrasqGyXNoguLUqbZX1bqqGquqsVWrVu3AEiVJM1na477Hgf0HllcDN05ulORJwFnAMVV1W4/1SJLmoM8jisuBA5OsSbI7cDxw/mCDJI8EzgNeVVXf67EWSdIc9XZEUVVbk7wZuAhYApxdVdcmOaXdvhb4c2AF8P4kAFuraqyvmiRJs5eqKYcNRtbY2FitX79+ocuQpJ1Kkivm+kHcK7MlSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1MmgkCR1MigkSZ0MCklSJ4NCktTJoJAkdTIoJEmdDApJUieDQpLUyaCQJHUyKCRJnQwKSVIng0KS1KnXoEhydJLvJtmQ5LQptifJe9vtVyd5cp/1SJJmr7egSLIEOBM4BjgEOCHJIZOaHQMc2N5OBj7QVz2SpLnp84jiCGBDVW2sqruBc4HjJrU5DvhINS4D9kny8B5rkiTN0tIe970fsGlgeRx46hBt9gNuGmyU5GSaIw6Au5J8a8eWutNaCdy60EWMCPtiG/tiG/tim8fN9YF9BkWmWFdzaENVrQPWASRZX1VjD7y8nZ99sY19sY19sY19sU2S9XN9bJ+nnsaB/QeWVwM3zqGNJGkB9RkUlwMHJlmTZHfgeOD8SW3OB05qv/30NOCnVXXT5B1JkhZOb6eeqmprkjcDFwFLgLOr6tokp7Tb1wIXAMcCG4A7gdcOset1PZW8M7IvtrEvtrEvtrEvtplzX6RquyEBSZJ+xSuzJUmdDApJUqeRDQqn/9hmiL44se2Dq5NcmuTQhahzPszUFwPtnpLk3iQvmc/65tMwfZHkyCRXJrk2yVfmu8b5MsTfyEOTfCbJVW1fDDMeutNJcnaSW6a71mzO75tVNXI3msHv7wOPBnYHrgIOmdTmWOBzNNdiPA34+kLXvYB98QzgYe39Y3blvhho9yWaL0u8ZKHrXsD/F/sA1wGPbJd/faHrXsC+eAfw7vb+KuB2YPeFrr2HvngW8GTgW9Nsn9P75qgeUTj9xzYz9kVVXVpVP24XL6O5HmUxGub/BcBbgE8At8xncfNsmL54BXBeVd0AUFWLtT+G6YsC9koS4CE0QbF1fsvsX1VdQvPapjOn981RDYrppvaYbZvFYLav83U0nxgWoxn7Isl+wO8Da+exroUwzP+Lg4CHJflykiuSnDRv1c2vYfriDODxNBf0XgO8tarum5/yRsqc3jf7nMLjgdhh038sAkO/ziTPoQmKZ/Za0cIZpi/eA5xaVfc2Hx4XrWH6YilwOHAUsAfwtSSXVdX3+i5ung3TFy8ArgSeCzwG+EKS/1tVP+u5tlEzp/fNUQ0Kp//YZqjXmeRJwFnAMVV12zzVNt+G6Ysx4Nw2JFYCxybZWlWfmpcK58+wfyO3VtUdwB1JLgEOBRZbUAzTF68F/mc1J+o3JPkBcDDwjfkpcWTM6X1zVE89Of3HNjP2RZJHAucBr1qEnxYHzdgXVbWmqg6oqgOAjwNvXIQhAcP9jXwa+O0kS5M8mGb25m/Pc53zYZi+uIHmyIok+9LMpLpxXqscDXN63xzJI4rqb/qPnc6QffHnwArg/e0n6a21CGfMHLIvdgnD9EVVfTvJhcDVwH3AWVW16KboH/L/xbuADyW5hub0y6lVteimH09yDnAksDLJOPBOYBk8sPdNp/CQJHUa1VNPkqQRYVBIkjoZFJKkTgaFJKmTQSFJ6mRQSJO0s85eOXCbdpbaOez7gOlm9pRG1UheRyEtsF9W1WELXYQ0KjyikIaU5Pok707yjfb22Hb9o5Jc3M7vf3F7pTxJ9k3yyfY3EK5K8ox2V0uSfLD9XYTPJ9ljwV6UNASDQtreHpNOPb18YNvPquoImtlI39OuO4Nm6uYnAR8F3tuufy/wlao6lOY3Aq5t1x8InFlVTwB+Ary411cjPUBemS1NkuQXVfWQKdZfDzy3qjYmWQbcXFUrktwKPLyq7mnX31RVK5NsBlZX1V0D+zgA+EJVHdgunwosq6q/mIeXJs2JRxTS7NQ096drM5W7Bu7fi2OFGnEGhTQ7Lx/492vt/UtpZiwFOBH4anv/YuANAEmWJNl7voqUdiQ/yUjb2yPJlQPLF1bVxFdkH5Tk6zQfsk5o1/0hcHaSPwE2s21GzrcC65K8jubI4Q3AYpwKX4ucYxTSkNoxirHFOD211MVTT5KkTh5RSJI6eUQhSepkUEiSOhkUkqROBoUkqZNBIUnq9P8BWD7YM8b3DFcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT MODEL HISTORY OF ACCURACY AND LOSS OVER EPOCHS\n",
    "#plt.plot(model_history.history['binary_accurancy'])\n",
    "#plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig('Initial_Model_Accuracy.png')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('Initial_Model_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e413a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine-learning]",
   "language": "python",
   "name": "conda-env-machine-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
